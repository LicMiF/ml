\item \subquestionpoints{18} {\bf Учење полинома трећег степена улазних података}

Нека је дат скуп података $\{(x^{(i)}, y^{(i)})\}_{i=1}^{\nexp}$ где $x^{(i)}, y^{(i)} \in \mathbb{R}$. Задатак је да се полином трећег степена $h_{\theta}(x) = \theta_3x^3 + \theta_2x^2 + \theta_1x^1 + \theta_0$ апроксимира скуп задати скуп података. Кључно запажање на овом месту јесте да је функција $h_{\theta}(x)$ и даље линеарна по непознатом параметру $\theta$ који се тражи, иако није линеарна по улазу $x$. Ово омогућава у наставку посматрање задатка као проблем линеарне регресије.

Нека је $\phi:\mathbb{R}\rightarrow \mathbb{R}^4$ функција која претвара изворне улазе $x$ у четвородимензионални вектор дефинисан као
\begin{align}
\phi(x) = \left[\begin{array}{c} 1\\ x \\ x^2 \\ x^3 \end{array}\right]\in \mathbb{R}^4 \label{eqn:feature}
\end{align}
Нека је $\hat{x}\in \mathbb{R}^4$ скраћени запис за $\phi(x)$, и нека је $\hat{x}^{(i)} \triangleq \phi(x^{(i)})$ трансформисани улаз из скупа тренинг података. Може се направити нови скуп података $\{(\phi(x^{(i)}), y^{(i)})\}_{i=1}^{\nexp} = \{(\hat{x}^{(i)}, y^{(i)})\}_{i=1}^{\nexp}$ заменом изворних улаза $x^{(i)}$ са $\hat{x}^{(i)}$. Може се приметити да је апроксимација кривом $h_{\theta}(x) = \theta_3x^3 + \theta_2x^2 + \theta_1x^1 + \theta_0$ почетног скупа података еквивалентна апроксимацији линеарном функцијом $h_{\theta}(\hat{x}) = \theta_3\hat{x}_3 +  \theta_2\hat{x}_2 + \theta_1\hat{x}_1 + \theta_0$ новодобијеног скупа података због тога што важи
\begin{align}
h_\theta(x) =  \theta_3x^3 + \theta_2x^2 + \theta_1x^1 + \theta_0 =  \theta_3 \phi(x)_3 + \theta_2\phi(x)_2 + \theta_1\phi(x)_1 + \theta_0 = \theta^T \hat{x}
\end{align}

Другим речима, може се искористити линеарна регресија над  новим скупом података да се одреде параметри $\theta_0,\dots, \theta_3$.

Написати 1) функцију губитака $J(\theta)$ за линеарни регресиони проблем над новим скупом података $\{(\hat{x}^{(i)}, y^{(i)})\}_{i=1}^{\nexp}$ и 2) правило за ажурирање у алгоритму потпуног (нестохастичког) градијентног спуста за линеарну регресију над скупом података $\{(\hat{x}^{(i)}, y^{(i)})\}_{i=1}^{\nexp}$.

\textit{Терминологија:} У машинском учењу, $\phi$ се често назива и пресликавање својстава које пресликава изворне улазе $x$ у нов скуп променљивих. Како би се направила разлика између ова два скупа променљивих, обично се $x$ називају улазни {\bf атрибути}, док се $\phi(x)$ називају {\bf особине} или {\bf својства}. (Нажалост, различити аутори користе различите термине да опишу ове две ствари.)

