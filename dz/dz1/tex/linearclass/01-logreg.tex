\item \subquestionpoints{20}

На предавањима је приказана функција губитака за логистичку регресију:
\begin{equation*}
	J(\theta)
	= -\frac{1}{\nexp} \sum_{i=1}^\nexp \left(y^{(i)}\log(h_{\theta}(x^{(i)}))
		+  (1 - y^{(i)})\log(1 - h_{\theta}(x^{(i)}))\right),
\end{equation*}
где је $y^{(i)} \in \{0, 1\}$, $h_\theta(x) = g(\theta^T x)$ и $g(z) = 1 / (1 + e^{-z})$.

Пронаћи Хесијан $H$ ове функције и показати да за произвољни вектор $z$ важи
%
\begin{equation*}
    z^T H z \ge 0.
\end{equation*}
%
{\bf Смерница:} Може се најпре показати да је $\sum_i\sum_j z_i x_i x_j z_j = (x^Tz)^2 \geq 0$. Подсетити се такође да је $g'(z) = g(z)(1-g(z))$.

{\bf Напомена:} Ово је један од уобичајених начина да се покаже да је матрица $H$ позитивно семидефинитна, што се означава са ``$H \succeq 0$.'' Ово даље имплицира да је $J$ конвексна, односно да нема других локалних минимума изузев глобалног. Није неопходно користити горњу смерницу како би се показало да је $H \succeq 0$ већ било коју.

